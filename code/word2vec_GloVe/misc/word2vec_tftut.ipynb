{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aneesh Joshi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "corpus_raw = 'He is the king . The king is royal . She is the royal  queen '\n",
    "\n",
    "# convert to lower case\n",
    "corpus_raw = corpus_raw.lower()\n",
    "\n",
    "words = []\n",
    "for word in corpus_raw.split():\n",
    "    if word != '.': # because we don't want to treat . as a word\n",
    "        words.append(word)\n",
    "\n",
    "words = set(words) # so that all duplicate words are removed\n",
    "word2int = {}\n",
    "int2word = {}\n",
    "vocab_size = len(words) # gives the total number of unique words\n",
    "\n",
    "for i,word in enumerate(words):\n",
    "    word2int[word] = i\n",
    "    int2word[i] = word\n",
    "\n",
    "# raw sentences is a list of sentences.\n",
    "raw_sentences = corpus_raw.split('.')\n",
    "sentences = []\n",
    "for sentence in raw_sentences:\n",
    "    sentences.append(sentence.split())\n",
    "\n",
    "WINDOW_SIZE = 2\n",
    "\n",
    "data = []\n",
    "for sentence in sentences:\n",
    "    for word_index, word in enumerate(sentence):\n",
    "        for nb_word in sentence[max(word_index - WINDOW_SIZE, 0) : min(word_index + WINDOW_SIZE, len(sentence)) + 1] : \n",
    "            if nb_word != word:\n",
    "                data.append([word, nb_word])\n",
    "\n",
    "# function to convert numbers to one hot vectors\n",
    "def to_one_hot(data_point_index, vocab_size):\n",
    "    temp = np.zeros(vocab_size)\n",
    "    temp[data_point_index] = 1\n",
    "    return temp\n",
    "\n",
    "x_train = [] # input word\n",
    "y_train = [] # output word\n",
    "\n",
    "for data_word in data:\n",
    "    x_train.append(to_one_hot(word2int[ data_word[0] ], vocab_size))\n",
    "    y_train.append(to_one_hot(word2int[ data_word[1] ], vocab_size))\n",
    "\n",
    "# convert them to numpy arrays\n",
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)\n",
    "\n",
    "# making placeholders for x_train and y_train\n",
    "x = tf.placeholder(tf.float32, shape=(None, vocab_size))\n",
    "y_label = tf.placeholder(tf.float32, shape=(None, vocab_size))\n",
    "\n",
    "EMBEDDING_DIM = 5 # you can choose your own number\n",
    "W1 = tf.Variable(tf.random_normal([vocab_size, EMBEDDING_DIM]))\n",
    "b1 = tf.Variable(tf.random_normal([EMBEDDING_DIM])) #bias\n",
    "hidden_representation = tf.add(tf.matmul(x,W1), b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, vocab_size]))\n",
    "b2 = tf.Variable(tf.random_normal([vocab_size]))\n",
    "prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_representation, W2), b2))\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init) #make sure you do this!\n",
    "\n",
    "# define the loss function:\n",
    "cross_entropy_loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), reduction_indices=[1]))\n",
    "\n",
    "# define the training step:\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy_loss)\n",
    "\n",
    "n_iters = 10000\n",
    "# train for n_iter iterations\n",
    "\n",
    "for _ in range(n_iters):\n",
    "    sess.run(train_step, feed_dict={x: x_train, y_label: y_train})\n",
    "    print('loss is : ', sess.run(cross_entropy_loss, feed_dict={x: x_train, y_label: y_train}))\n",
    "\n",
    "vectors = sess.run(W1 + b1)\n",
    "\n",
    "def euclidean_dist(vec1, vec2):\n",
    "    return np.sqrt(np.sum((vec1-vec2)**2))\n",
    "\n",
    "def find_closest(word_index, vectors):\n",
    "    min_dist = 10000 # to act like positive infinity\n",
    "    min_index = -1\n",
    "    query_vector = vectors[word_index]\n",
    "    for index, vector in enumerate(vectors):\n",
    "        if euclidean_dist(vector, query_vector) < min_dist and not np.array_equal(vector, query_vector):\n",
    "            min_dist = euclidean_dist(vector, query_vector)\n",
    "            min_index = index\n",
    "    return min_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "model = TSNE(n_components=2, random_state=0)\n",
    "np.set_printoptions(suppress=True)\n",
    "vectors = model.fit_transform(vectors) \n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "normalizer = preprocessing.Normalizer()\n",
    "vectors =  normalizer.fit_transform(vectors, 'l2')\n",
    "\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'he', 'the', 'is', 'she', 'king', 'queen', 'royal'}\n",
      "he -0.9162855\n",
      "the -0.99240047\n",
      "is -0.40979075\n",
      "she -0.93926716\n",
      "king 0.8122346\n",
      "queen -0.2979713\n",
      "royal 0.5759811\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "print(words)\n",
    "for word in words:\n",
    "    print(word, vectors[word2int[word]][1])\n",
    "    ax.annotate(word, (vectors[word2int[word]][0],vectors[word2int[word]][1] ))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
