{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mahmood Amintoosi, محمود امین طوسی\n",
    "طبقه‌بندی داده های همشهری"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd \n",
    "  \n",
    "loc = (\"../data/datasetMAT.xlsx\") \n",
    "  \n",
    "wb = xlrd.open_workbook(loc) \n",
    "sheet = wb.sheet_by_index(0) \n",
    "sheet.cell_value(0, 0) \n",
    "\n",
    "docs = [None] * sheet.nrows\n",
    "labels = [None] * sheet.nrows\n",
    "for i in range(sheet.nrows): \n",
    "    docs[i] = sheet.cell_value(i, 0)\n",
    "    labels[i] = sheet.cell_value(i, 1)\n",
    "#     print(i,sheet.cell_value(i, 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_docs, test_docs, train_labels, test_labels = train_test_split(docs, labels, test_size=0.999, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hazm\n",
    "from hazm import stopwords_list\n",
    "from hazm import sent_tokenize, word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "stop_words = stopwords_list()\n",
    "# stop_words[0:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenisation\n",
    "vectorizer = TfidfVectorizer(stop_words=stop_words,\n",
    "                             tokenizer=word_tokenize)\n",
    " \n",
    "# Learn and transform train documents\n",
    "vectorised_train_documents = vectorizer.fit_transform(train_docs)\n",
    "vectorised_test_documents = vectorizer.transform(test_docs)\n",
    " \n",
    "# Transform multilabel labels\n",
    "mlb = MultiLabelBinarizer()\n",
    " \n",
    "# Classifier\n",
    "classifier = OneVsRestClassifier(LinearSVC(random_state=42))\n",
    "classifier.fit(vectorised_train_documents, train_labels)\n",
    " \n",
    "predictions = classifier.predict(vectorised_test_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-average quality numbers\n",
      "Precision: 0.6577, Recall: 0.6577, F1-measure: 0.6577\n",
      "Macro-average quality numbers\n",
      "Precision: 0.7964, Recall: 0.6578, F1-measure: 0.6124\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,precision_score,recall_score\n",
    " \n",
    "precision = precision_score(test_labels, predictions,\n",
    "                            average='micro')\n",
    "recall = recall_score(test_labels, predictions,\n",
    "                      average='micro')\n",
    "f1 = f1_score(test_labels, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\"\n",
    "        .format(precision, recall, f1))\n",
    " \n",
    "precision = precision_score(test_labels, predictions,\n",
    "                            average='macro')\n",
    "recall = recall_score(test_labels, predictions,\n",
    "                      average='macro')\n",
    "f1 = f1_score(test_labels, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\"\n",
    "        .format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.io as sio\n",
    "# sio.savemat('hamshahri.mat', {'X_train':vectorised_train_documents,'train_labels':train_labels,'X_test':vectorised_test_documents,'test_labels':test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_labels[0:5], predictions[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10x824 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1089 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorised_train_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['و',\n",
       " 'در',\n",
       " 'به',\n",
       " 'از',\n",
       " 'که',\n",
       " 'این',\n",
       " 'را',\n",
       " 'با',\n",
       " 'است',\n",
       " 'برای',\n",
       " 'آن',\n",
       " 'یک',\n",
       " 'خود',\n",
       " 'تا',\n",
       " 'کرد',\n",
       " 'بر',\n",
       " 'هم',\n",
       " 'نیز',\n",
       " 'گفت',\n",
       " 'می\\u200cشود']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words[0:20] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
